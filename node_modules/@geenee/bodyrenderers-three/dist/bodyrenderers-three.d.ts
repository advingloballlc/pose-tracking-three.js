import { SceneRenderer, CanvasMode, Size, ScenePlugin, Renderer, VideoPlugin } from '@geenee/armature';
import { PoseResult, FaceResult, PosePoints } from '@geenee/bodyprocessors';
import * as three from 'three';
import { Coord3D, Coord2D } from '@geenee/bodytracking';

/**
 * Generic three.js renderer
 *
 * Extends {@link @geenee/armature!SceneRenderer} for the three.js
 * rendering engine. ThreeRenderer does basic initialization of
 * engine, scene, and camera. It's a generic class that should be
 * parameterized by type of processing results to build an app using
 * particular implementation of {@link @geenee/armature!Processor}.
 *
 * @typeParam ResultT - Type of processing results
 */
declare class ThreeRenderer<ResultT extends {} = {}> extends SceneRenderer<ResultT, three.Scene> {
    /** Rendering engine */
    protected renderer: three.WebGLRenderer;
    /** Camera instance */
    protected camera: three.Camera;
    /** Camera's vertical angle of view */
    protected cameraAngle: number;
    /**
     * Constructor
     *
     * @param container - Container of {@link @geenee/armature!ResponsiveCanvas}
     * @param mode - Fitting mode
     * @param mirror - Mirror the output
     */
    constructor(container: HTMLElement, mode?: CanvasMode, mirror?: boolean);
    /**
     * Update and render the scene
     *
     * Virtual method updating and rendering 3D scene.
     * Basic implementation for three.js engine calls
     * `this.renderer.render(this.scene, this.camera)`.
     *
     * @override
     */
    protected updateScene(): void;
    /**
     * Set camera parameters
     *
     * Setups {@link ThreeRenderer#camera} instance according to
     * parameters provided by {@link @geenee/armature!Processor}.
     *
     * @param size - Resolution of input video
     * @param ratio - Aspect ration of input video
     * @override
     */
    setupCamera(ratio: number, angle: number): void;
    /**
     * Set camera parameters
     *
     * If {@link ThreeRenderer#camera} is OrthographicCamera sets
     * orthographic projection according to resolution of video.
     *
     * @param size - Resolution of input video
     * @param ratio - Aspect ration of input video
     * @override
     */
    setupVideo(size: Size, ratio?: number): void;
    /**
     * Dispose object
     *
     * Helper method to remove object from the scene and
     * recursively dispose it with all its children and
     * allocated resources like materials and textures.
     *
     * @param object - Object to dispose
     */
    protected disposeObject(object: three.Object3D): void;
}
/**
 * Generic plugin for {@link ThreeRenderer}
 *
 * Extends {@link @geenee/armature!ScenePlugin} for the three.js
 * rendering engine. ThreePlugin is an abstract generic class
 * simplifying library's API, it doesn't implement any logic and
 * can be used as basis for actual render plugins. It should be
 * parameterized by type of processing results to build a plugin
 * for the implementation of {@link @geenee/armature!Processor}.
 *
 * @typeParam ResultT - Type of processing results
 */
declare class ThreePlugin<ResultT extends {} = {}> extends ScenePlugin<ResultT, three.Scene> {
}
/**
 * Abstract renderer for {@link @geenee/bodyprocessors!PoseProcessor}
 *
 * Specializes the {@link ThreeRenderer} generic for
 * {@link @geenee/bodyprocessors!PoseResult}. This is
 * abstract renderer that doesn't implement any logic.
 */
declare class PoseRenderer extends ThreeRenderer<PoseResult> {
}
/**
 * Abstract plugin for {@link PoseRenderer}
 *
 * Specializes the {@link ThreePlugin} generic for
 * {@link @geenee/bodyprocessors!PoseResult}. This's
 * abstract plugin that doesn't implement any logic.
 */
declare class PosePlugin extends ThreePlugin<PoseResult> {
}
/**
 * Abstract renderer for {@link @geenee/bodyprocessors!FaceProcessor}
 *
 * Specializes the {@link ThreeRenderer} generic for
 * {@link @geenee/bodyprocessors!FaceResult}. This is
 * abstract renderer that doesn't implement any logic.
 */
declare class FaceRenderer extends ThreeRenderer<FaceResult> {
}
/**
 * Abstract plugin for {@link FaceRenderer}
 *
 * Specializes the {@link ThreePlugin} generic for
 * {@link @geenee/bodyprocessors!FaceResult}. This's
 * abstract plugin that doesn't implement any logic.
 */
declare class FacePlugin extends ThreePlugin<FaceResult> {
}

/**
 * Plugin assigning head pose to a scene node
 *
 * Plugin attaches provided scene node to the head.
 * Pose of the node (translation + rotation + scale)
 * continuously updates according to pose estimation
 * by {@link @geenee/bodyprocessors!FaceProcessor}.
 * Children nodes inherently include this transform.
 * The node can be seen as a virtual placeholder for
 * real object. It's recommended to attach top-level
 * nodes that don't include transforms relative to
 * parent, otherwise head transform that is a pose
 * in the world frame will be applied on top of them
 * (will be treated as relative instead of absolute).
 * Optionally anisotropic fine-tuning of the scale can
 * be applied. In this case model will additionally
 * adapt to shape of the face. If face isn't detected
 * by FaceProcessor plugin recursively hides the node.
 * One of approaches to accurately align meshes with
 * a face/head when modeling a scene is to make them
 * children of one node at the origin and set their
 * relative transforms using face/head base mesh as
 * the reference, then instantiate HeadTrackPlugin
 * for this scene node. You can also apply relative
 * transforms of children of the head-attached parent
 * node programmatically. It's useful to add occluder
 * model (base mesh of a head) as a child of the node.
 * Another possible but less scalable approach is to
 * have all meshes be built relative to the origin and
 * aligned with the base mesh of face/head, in this
 * case you can create HeadTrackPlugin for each mesh.
 * This can be handy when parts are stored separately.
 */
declare class HeadTrackPlugin extends ThreePlugin<FaceResult> {
    protected node: three.Object3D;
    protected shapeScale: boolean;
    /**
     * Constructor
     *
     * @param node - Scene node to attach
     * @param shapeScale - Tune scale according to shape of the face
     */
    constructor(node: three.Object3D, shapeScale?: boolean);
    /**
     * Update pose of the node
     *
     * Updates node's transform (translation+rotation+scale) according to
     * the pose estimated by {@link @geenee/bodyprocessors!FaceProcessor}.
     * If face isn't detected plugin recursively hides the attached node.
     *
     * @param result - Results of video processing
     * @param stream - Captured video frame
     * @returns Promise resolving when update is finished
     * @override
     */
    update(result: FaceResult, stream: HTMLCanvasElement): Promise<void>;
}

/**
 * Plugin assigning face point pose to a scene node
 *
 * Plugin attaches provided node to the face point.
 * Pose of the node (translation + rotation + scale)
 * continuously updates according to pose estimation
 * by {@link @geenee/bodyprocessors!FaceProcessor}.
 * Children nodes inherently include this transform.
 * The node can be seen as a virtual placeholder for
 * real object. It's recommended to attach top-level
 * nodes that don't include transforms relative to
 * parent, otherwise head transform that is a pose
 * in the world frame will be applied on top of them
 * (will be treated as relative instead of absolute).
 * Optionally anisotropic fine-tuning of the scale can
 * be applied. In this case model will additionally
 * adapt to shape of the face. If face isn't detected
 * by FaceProcessor plugin recursively hides the node.
 * One of approaches to accurately align meshes with
 * a face point when modeling a scene is to make them
 * children of a node which origin coincide with the
 * corresponding vertex of the reference face mesh,
 * set their relative transforms using base mesh as
 * the reference, then instantiate FaceTrackPlugin
 * for this scene node. You can also apply relative
 * transforms of children of the face-attached parent
 * node programmatically. It's useful to add occluder
 * model (base mesh of a head) as a child of the node.
 * This can be handy when parts are stored separately.
 */
declare class FaceTrackPlugin extends ThreePlugin<FaceResult> {
    protected node: three.Object3D;
    protected facePoint: number;
    protected shapeScale: boolean;
    /**
     * Constructor
     *
     * @param node - Scene node to attach
     * @param facePoint - Index of the face vertex
     * @param shapeScale - Tune scale according to shape of the face
     */
    constructor(node: three.Object3D, facePoint?: number, shapeScale?: boolean);
    /**
     * Update pose of the model
     *
     * Updates node's pose (translation + rotation + scale) according to
     * to the estimation from {@link @geenee/bodyprocessors!FaceProcessor}.
     * If face isn't detected plugin recursively hides the attached node.
     *
     * @param result - Results of video processing
     * @param stream - Captured video frame
     * @returns Promise resolving when update is finished
     * @override
     */
    update(result: FaceResult, stream: HTMLCanvasElement): Promise<void>;
}

/**
 * Plugin assigning face mesh to geometry to a scene node
 *
 * Plugin controls geometry of a scene node. Vertices are
 * continuously updated using face mesh points estimated
 * by {@link @geenee/bodyprocessors!FaceProcessor}. Node's
 * mesh must have geometry compatible with detected face
 * mesh, preferably created from the reference face model.
 * The main requirement is that uv map must be compatible.
 * The node can be seen as a virtual placeholder for real
 * object. It's recommended to attach top-level nodes that
 * don't have transforms relative to the root, otherwise
 * this transforms will be applied to absolute positions
 * of 3d points of the face (points will act as relative).
 * One of approaches to create node for accurate face mask
 * when modeling a scene is to import reference face model
 * as top-level scene node and add one or more materials
 * which textures are compatible with reference's uv map.
 * And then instantiate FaceMaskPlugin for this scene node.
 * In {@link FaceMaskPlugin#load | load()} plugin replaces
 * geometry of attached node's mesh with one provided by
 * FaceProcessor, defined indices, uv mapping and normals.
 * As soon as uv maps of the scene mesh and the reference
 * model are compatible all materials will be applied the
 * same way as in the modeled scene. Vertices positions
 * are updated in {@link FaceMaskPlugin#update | update()}
 * method according to current face tracking estimations.
 */
declare class FaceMaskPlugin extends ThreePlugin<FaceResult> {
    protected mesh?: three.Mesh<three.BufferGeometry, three.Material | three.Material[]> | undefined;
    /** Number of points in detected mesh */
    readonly pointCont: number;
    /**
     * Constructor
     *
     * @param mesh - Scene mesh to attach
     */
    constructor(mesh?: three.Mesh<three.BufferGeometry, three.Material | three.Material[]> | undefined);
    /**
     * Initialize plugin
     *
     * FaceMaskPlugin replaces geometry of attached mesh
     * by compatible with face estimated by FaceProcessor.
     * As soon as uv maps of the node and the reference
     * face model are compatible, materials/textures will
     * be applied the same way as in the modeled 3d scene.
     * Defines indices, uvs, normals, while positions are
     * updated in {@link FaceMaskPlugin#update | update()}.
     *
     * @param renderer - Renderer this plugin is attached to
     * @returns Promise resolving when initialization is finished
     * @override
     */
    load(renderer: Renderer<FaceResult>): Promise<void>;
    /**
     * Update geometry of the mesh
     *
     * Updates vertex positions according to points of the face
     * estimated by {@link @geenee/bodyprocessors!FaceProcessor}.
     * If face is not detected, plugin hides the attached mesh.
     *
     * @param result - Results of video processing
     * @param stream - Captured video frame
     * @returns Promise resolving when update is finished
     * @override
     */
    update(result: FaceResult, stream: HTMLCanvasElement): Promise<void>;
    /**
     * Set/attach a scene mesh
     *
     * Rebuilds geometry of the mesh node to be compatible
     * with face mesh points estimated by FaceProcessor.
     * As soon as uv maps of the node and the reference
     * face model are compatible, materials/textures will
     * be applied the same way as in the modeled 3d scene.
     *
     * @param mesh - Scene mesh node to attach
     * @returns Promise resolving when initialization is finished
     * @virtual
     */
    setMesh(mesh?: three.Mesh): Promise<void>;
}

declare class FaceDebugPlugin extends VideoPlugin<FaceResult> {
    update(result: FaceResult, stream: HTMLCanvasElement): Promise<void>;
    protected drawPath(videoCtx: CanvasRenderingContext2D, points: Coord3D[], close?: boolean): void;
}

/** Bones of the rig */
interface SkeletonRef {
    hips: three.Bone;
    spine: three.Bone;
    spine1: three.Bone;
    spine2: three.Bone;
    neck: three.Bone;
    head: three.Bone;
    headEnd: three.Bone;
    shoulderL: three.Bone;
    shoulderR: three.Bone;
    armL: three.Bone;
    armR: three.Bone;
    foreArmL: three.Bone;
    foreArmR: three.Bone;
    handL: three.Bone;
    handR: three.Bone;
    upLegL: three.Bone;
    upLegR: three.Bone;
    legL: three.Bone;
    legR: three.Bone;
    footL: three.Bone;
    footR: three.Bone;
    toeL: three.Bone;
    toeR: three.Bone;
}
/** Bone transformation */
interface Bone {
    /** Head position */
    position: three.Vector3;
    /** Bone orientation */
    rotation: three.Quaternion;
}
/** Skeleton transformations */
interface Skeleton {
    hips: Bone;
    spine: Bone;
    spine1: Bone;
    spine2: Bone;
    neck: Bone;
    head: Bone;
    headEnd: Bone;
    shoulderL: Bone;
    armL: Bone;
    foreArmL: Bone;
    handL: Bone;
    shoulderR: Bone;
    armR: Bone;
    foreArmR: Bone;
    handR: Bone;
    upLegL: Bone;
    legL: Bone;
    footL: Bone;
    toeL: Bone;
    upLegR: Bone;
    legR: Bone;
    footR: Bone;
    toeR: Bone;
}
/** Shape of spine
 *
 * Used by {@link PoseAlignPlugin} internally
 * to fine-tune curvature of spine skeleton.
 */
interface Spine {
    spine: Coord2D;
    spine1: Coord2D;
    spine2: Coord2D;
    head: Coord2D;
}
/**
 * Parameters of pose fine-tuning
 *
 * These parameters control optional adjustments added to basic
 * pose-model alignment method. {@link PoseAlignPlugin} supports
 * rigs compatible with Mixamo armature (Ready Player Me avatars).
 * This is the most common armature standard for human-like models,
 * supported by many game engines. But for example models rigged
 * and skinned manually or using Mixamo tool can variate depending
 * on anthropomorphous model topology, e.g. animated characters
 * can have disproportional body parts like a much bigger head.
 * In such cases fine-tuning may be required. Also depending on
 * use case you can try several options and see what works better.
 * As an example turning off adjustment of spine curvature gives
 * better results in virtual garment try-on experiences, while for
 * full-body avatar overlaying it can provide more natural look.
 */
interface PoseTuneParams {
    /**
     * Pose plugin can adjust estimated spine skeleton resembling
     * curvature of model's spine in rest (default) pose. In other
     * words it slightly modifies bone positions and rotations to
     * mimic spine curve. Parameter is a number, usually in range
     * [0..1]. 0 or undefined means spine of the rig will remain
     * flat (default estimation), while 1 - rig's curvature is
     * projected completely. Values in between control strength
     * of curvature and values bigger than 1.0 will amplify it.
     */
    spineCurve?: number;
    /**
     * In some cases it can be useful to adjust positions of
     * shoulders making them slightly wider, higher or deeper.
     * This adjustment helps to adapt model to proportions of
     * human body or to make sure body is completely covered.
     * `shoulderDX` adjusts width of shoulders, it's shift in
     * meters, we recommend values of 0.01 order of magnitude.
     * Default value is 0 meaning shoulders are not adjusted.
     */
    shoulderDX?: number;
    /**
     * In some cases it can be useful to adjust positions of
     * shoulders making them slightly wider, higher or deeper.
     * This adjustment helps to adapt model to proportions of
     * human body or to make sure body is completely covered.
     * `shoulderDY` adjusts height of shoulders, it's shift in
     * meters, we recommend values of 0.01 order of magnitude.
     * Default value is 0 meaning shoulders are not adjusted.
     */
    shoulderDY?: number;
    /**
     * In some cases it can be useful to adjust positions of
     * shoulders making them slightly wider, higher or deeper.
     * This adjustment helps to adapt model to proportions of
     * human body or to make sure body is completely covered.
     * `shoulderDZ` adjusts depth of shoulders, it's shift in
     * meters, we recommend values of 0.01 order of magnitude.
     * Default value is 0 meaning shoulders are not adjusted.
     */
    shoulderDZ?: number;
    /**
     * In many models head of shoulder's bone doesn't coincide
     * with tail of the parent. This parameter defines distance
     * from head of the neck bone to head of the shoulder bone
     * ratio to distance to tail of shoulder. Value should be
     * in range [0..1], default value for most models is 0.2
     */
    shoulderOffset?: number;
    /**
     * Distance between center of the head defined by midpoint
     * of ears and position of the head bone (its start) ratio
     * to overall length of head bone. Relative lengths of neck
     * and head bones vary a lot between human-like models. It
     * is not possible to automatically find where ears or the
     * model's mesh are so this value provides a way to define it.
     * Recommended range is [0.3 .. 0.5], default value is 0.35
     * that close to topology of all Ready Player Me avatars.
     */
    headRatio?: number;
    /**
     * Advanced adjustment of the neck bone. Naturally base of
     * a neck is not exactly center between shoulders, it shifts
     * depending on direction of shoulder bones. This parameter
     * defines magnitude of this shift in meters. Recommended
     * values are 0.01 order of magnitude. Default is undefined.
     */
    neckAdjust?: number;
}
/**
 * Pose plugin aligning node's rig with keypoints
 *
 * Universal plugin aligning node's rig and pose estimated by
 * {@link @geenee/bodyprocessors!PoseProcessor}. It's a base of
 * try-on, twin, and other plugins. You can use this class as a
 * starting point and customize alignment method or add features.
 * Basically, PoseAlignPlugin evaluates positions and rotations
 * of armature bones based on 3D pose keypoints, then applies
 * these transforms to bones following the armature hierarchy.
 * Plugin supports rigs compatible with Mixamo, for example any
 * Ready Player Me avatar. This is the most common standard of
 * rigs for human-like models supported by many game engines.
 * Provided node must contain an armature among its children.
 * Armature bones must follow Mixamo / RPM naming convention.
 * Models rigged and skinned manually or using Mixamo tool can
 * variate depending on anthropomorphous topology of the model.
 * PoseAlignPlugin can apply number of fine-tuning adjustments
 * to basic alignment improving model fitting or making it look
 * more natural. {@link PoseTuneParams} explains tuning options.
 * By default the plugin is fine-tuned for RPM avatars so you
 * can simply replace person with the avatar model in the scene.
 */
declare class PoseAlignPlugin extends PosePlugin {
    protected node?: three.Object3D<three.Event> | undefined;
    protected tune: PoseTuneParams;
    /** Bones of the model's rig */
    protected skeleton?: SkeletonRef;
    /** Reference to model's skeleton */
    protected skeletonRef?: three.Skeleton;
    /** Shape of spine */
    protected spineRef?: Spine;
    /** Reference length of the model */
    protected avatarLength: number;
    /** Pose score threshold */
    readonly alignScore = 0.9;
    /** Keypoint visibility threshold */
    readonly alignVisibility = 0.9;
    /**
     * Constructor
     *
     * @param node - Scene node to attach
     * @param tune - Fine-tuning parameters
     */
    constructor(node?: three.Object3D<three.Event> | undefined, tune?: PoseTuneParams);
    /**
     * Initialize plugin
     *
     * Parses and caches the rig/armature of the attached
     * scene node (one provided to plugin's constructor).
     * Precalculates geometrical parameters of skeleton.
     *
     * @param renderer - Renderer this plugin is attached to
     * @returns Promise resolving when initialization is finished
     * @override
     */
    load(renderer: Renderer<PoseResult>): Promise<void>;
    /**
     * Reset plugin
     *
     * Removes the attached node.
     *
     * @override
     */
    unload(): void;
    /**
     * Set/attach a scene node
     *
     * Parses and caches the rig/armature of the node.
     * Precalculates geometrical parameters of skeleton.
     *
     * @param node - Scene node to attach
     * @returns Promise resolving when initialization is finished
     * @virtual
     */
    setNode(node?: three.Object3D): void;
    /**
     * Update skeleton of the scene node
     *
     * Evaluates positions, rotations and scales of node bones
     * based on estimation of 3D keypoints, then applies these
     * transformations to bones following hierarchy of armature.
     * Optionally {@link PoseTuneParams | fine-tunes} the basic
     * alignment to improve model fitting or make it more natural.
     * You can override this method to further tune model's rig
     * using provided estimations of bones as starting point.
     * Simply call `await super.update(result, stream);` and use
     * {@link PoseAlignPlugin#skeletonRef} member storing refs
     * to all bones of the skeleton to access transformations.
     *
     * @param result - Pose estimation results
     * @param stream - Captured video frame
     * @returns Promise resolving when update is finished
     * @override
     */
    update(result: PoseResult, stream: HTMLCanvasElement): Promise<void>;
    /**
     * Update spine skeleton
     *
     * @param anchors - Positions and axes of bones
     */
    protected updateSpine(anchors: Skeleton): void;
    /**
     * Update left hand skeleton
     *
     * @param anchors - Positions and axes of bones
     * @param points - Pose keypoints
     */
    protected updateHandL(anchors: Skeleton, points: PosePoints): void;
    /**
     * Update right hand skeleton
     *
     * @param anchors - Positions and axes of bones
     * @param points - Pose keypoints
     */
    protected updateHandR(anchors: Skeleton, points: PosePoints): void;
    /**
     * Update left leg skeleton
     *
     * @param anchors - Positions and axes of bones
     * @param points - Pose keypoints
     */
    protected updateLegL(anchors: Skeleton, points: PosePoints): void;
    /**
     * Update right leg skeleton
     *
     * @param anchors - Positions and axes of bones
     * @param points - Pose keypoints
     */
    protected updateLegR(anchors: Skeleton, points: PosePoints): void;
    /**
     * Estimate bone positions and axes
     *
     * Based on detected keypoints estimates bone transformations.
     * Position of bone if defined by 3D point itself, bone length
     * is the distance between keypoints connected by bone. Bone's
     * rotation is defined by its axes that are evaluated from
     * relative positions of adjacent keypoints. Method returns
     * only bone position and orientation axis, final transformation
     * of any bone can be found using the next bone in hierarchy.
     *
     * @param points - Pose keypoints
     * @param spineRef - Shape of spine
     * @returns Bone transformations
     */
    protected estimateBones(points: PosePoints, spineRef: Spine): Skeleton;
    /**
     * Estimate bone position and orientation
     *
     * Position/translation of bone is defined by its head.
     * Rotation is defined by bone's basis axes, vector from
     * head to tail gives Y axis, X axis is provided, Z axis
     * is evaluated to form right-handed orthonormal basis.
     *
     * @param head - Bone's head (position)
     * @param tail - Bone's tail (end)
     * @param axisX - Direction of X axis
     * @returns Bone transformation
     */
    private estimateBone;
    /**
     * Set bone transformation
     *
     * Transformation is in the world coordinate frame. If bone
     * has parent we find relative transformation to follow the
     * skeleton hierarchy. Optionally scale of parent bone can
     * be adjusted to align head and reference (rest) position
     * of parent's tail (they have to be the same 3D point).
     *
     * @param transform - Global bone position and rotation
     * @param bone - Reference to bone instance
     * @param scale - Whether to scale parent bone
     * @virtual
     */
    protected alignBone(transform: Bone, bone: three.Bone, scale?: boolean): void;
}

/**
 * Outfit options
 *
 * Defines occluder and hidden meshes of the node.
 * Names of meshes are provided as strings or regex.
 * If name of a child mesh equals string or matches
 * regex it's assigned the corresponding type. All
 * other meshes are assumed to be visible as usual.
 */
interface OutfitParams {
    /** Occluder meshes */
    occluders?: (string | RegExp)[];
    /** Hidden meshes */
    hidden?: (string | RegExp)[];
}
/**
 * Plugin implementing virtual try-on of avatar's outfit
 *
 * PoseOutfitPlugin is extension of {@link PoseAlignPlugin}
 * that allows to specify body meshes of the avatar's node
 * as occluders and optionally hide some child meshes (parts).
 * It's a good starting point for virtual try-on applications.
 * {@link OutfitParams} defines available options of outfit.
 * You can download any Ready Player Me avatar which outfit
 * similar to final result, edit its outfit, re-skin model if
 * necessary. Then simply use this plugin to build try-on app.
 * Armature bones must follow Mixamo / RPM naming convention.
 */
declare class PoseOutfitPlugin extends PoseAlignPlugin {
    protected outfit?: OutfitParams | undefined;
    /**
     * Constructor
     *
     * @param node - Scene node to attach
     * @param outfit - Occluder and hidden parts
     * @param tune - Fine-tuning parameters
     */
    constructor(node?: three.Object3D, outfit?: OutfitParams | undefined, tune?: PoseTuneParams);
    /**
     * Set/attach a scene node
     *
     * Method setNode() is extended to make occluders from specified
     * body meshes and optionally hide some child meshes according to
     * {@link OutfitParams | parameters}. Occluders are made the same
     * way {@link OccluderPlugin} does via overriding mesh materials.
     *
     * @param object - Scene node to attach
     * @returns Promise resolving when initialization is finished
     * @override
     */
    setNode(object?: three.Object3D): void;
    /**
     * Set outfit parameters
     *
     * @param node - Scene node to attach
     * @param outfit - Occluder and hidden parts
     * @returns Promise resolving when initialization is finished
     */
    setOutfit(node?: three.Object3D, outfit?: OutfitParams): void;
}

/**
 * Plugin rendering a digital twin
 *
 * {@link PoseAlignPlugin} extension for digital twins mirroring
 * the pose and residing beside a user. When rendering a twin we
 * do not translate bones to align with keypoint coordinates and
 * only preserve relative rotations. After projecting the detected
 * pose onto a twin, twin's scene node can be further transformed
 * relative to the initial position - centers of hips are the same.
 */
declare class PoseTwinPlugin extends PoseAlignPlugin {
    protected translation?: three.Vector3 | undefined;
    protected rotation?: three.Quaternion | undefined;
    protected scale?: number | undefined;
    /**
     * Constructor
     *
     * @param node - Scene node to attach
     * @param translation - Relative translation of the twin
     * @param rotation - Relative rotation of the twin
     * @param scale - Scale of the twin
     * @param tune - Fine-tuning parameters
     */
    constructor(node?: three.Object3D, translation?: three.Vector3 | undefined, rotation?: three.Quaternion | undefined, scale?: number | undefined, tune?: PoseTuneParams);
    /**
     * Update skeleton of the scene node
     *
     * Method is extended to set twin's translation,
     * rotation, and scale relative to estimated pose.
     *
     * @param result - Pose estimation results
     * @param stream - Captured video frame
     * @returns Promise resolving when update is finished
     * @override
     */
    update(result: PoseResult, stream: HTMLCanvasElement): Promise<void>;
    /**
     * Update spine skeleton
     *
     * Overridden to ignore relative scaling.
     *
     * @param anchors - Positions and axes of bones
     * @override
     */
    protected updateSpine(anchors: Skeleton): void;
    /**
     * Set bone aligning transformation
     *
     * Overridden to assign only relative rotation.
     *
     * @param transform - Global bone position and rotation
     * @param bone - Reference to bone instance
     * @override
     */
    protected alignBone(transform: Bone, bone: three.Bone): void;
}

/**
 * Occluder plugin
 *
 * Plugin making provided node an occluder. Usually
 * node is a base mesh (average approximation) of a
 * body representing its real counterpart in a scene.
 * Occluders are not rendered by themselves but still
 * participate in occlusion queries. This is achieved
 * by setting `colorWrite=false` to all materials of
 * node's meshes. This flag tells rendering engine to
 * not write to color buffer but still write to depth
 * buffer. Then meshes are effectively not rendered
 * (fragment color write is skipped) and only occlude
 * all other meshes of the scene (during depth test).
 */
declare class OccluderPlugin extends ThreePlugin<any> {
    protected node: three.Object3D;
    protected renderOrder: number;
    /**
     * Constructor
     *
     * @param node - Scene node of an occluder
     * @param renderOrder - Render order (0,1,2,3)
     */
    constructor(node: three.Object3D, renderOrder?: number);
    /**
     * Initialize plugin
     *
     * Sets `colorWrite=false` to all node's materials.
     * This tells rendering engine to not write to color
     * buffer, but still write to depth buffer. This way
     * mesh is effectively not drawn (color buffer) but
     * occludes other meshes of the scene (depth test).
     *
     * @param renderer - Renderer this plugin is attached to
     * @returns Promise resolving when initialization is finished
     * @override
     */
    load(renderer: Renderer<any>): Promise<void>;
}

export { Bone, FaceDebugPlugin, FaceMaskPlugin, FacePlugin, FaceRenderer, FaceTrackPlugin, HeadTrackPlugin, OccluderPlugin, OutfitParams, PoseAlignPlugin, PoseOutfitPlugin, PosePlugin, PoseRenderer, PoseTuneParams, PoseTwinPlugin, Skeleton, ThreePlugin, ThreeRenderer };
